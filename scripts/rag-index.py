#!/usr/bin/env python3
"""
rag-index.py - RAGæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆãƒ»æ¤œç´¢ï¼‰
"""

import sys
import json
import os
from pathlib import Path
import numpy as np

# sentence-transformersã¨FAISSã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from sentence_transformers import SentenceTransformer
    import faiss
except ImportError as e:
    print(f"âš ï¸ å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“: {e}")
    print("ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:")
    print("  source /root/venv/bin/activate && pip install sentence-transformers faiss-cpu numpy")
    sys.exit(1)

# è¨­å®š
KNOWLEDGE_DIR = Path("/root/clawd/knowledge")
INDEX_FILE = KNOWLEDGE_DIR / "embeddings.index"
METADATA_FILE = KNOWLEDGE_DIR / "metadata.json"
MODEL_NAME = "all-MiniLM-L6-v2"  # è»½é‡ã§é«˜é€Ÿãªãƒ¢ãƒ‡ãƒ«

class RAGSystem:
    def __init__(self):
        self.model = None
        self.index = None
        self.metadata = []
        
    def load_model(self):
        """åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿"""
        if self.model is None:
            print(f"ğŸ”„ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­: {MODEL_NAME}")
            self.model = SentenceTransformer(MODEL_NAME)
            print("âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
    
    def chunk_text(self, text: str, chunk_size: int = 500) -> list[str]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²"""
        # æ”¹è¡Œã§åˆ†å‰²ã—ã¦ã€ç©ºè¡Œã‚’å‰Šé™¤
        lines = [line.strip() for line in text.split('\n') if line.strip()]
        
        chunks = []
        current_chunk = []
        current_size = 0
        
        for line in lines:
            line_size = len(line)
            if current_size + line_size > chunk_size and current_chunk:
                chunks.append('\n'.join(current_chunk))
                current_chunk = [line]
                current_size = line_size
            else:
                current_chunk.append(line)
                current_size += line_size
        
        if current_chunk:
            chunks.append('\n'.join(current_chunk))
        
        return chunks
    
    def create_index(self, file_paths: list[str]):
        """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ"""
        self.load_model()
        
        all_chunks = []
        metadata = []
        
        print(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ä¸­...")
        for file_path in file_paths:
            path = Path(file_path)
            if not path.exists():
                print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {file_path}")
                continue
            
            print(f"  - {path.name}")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            with open(path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
            chunks = self.chunk_text(content)
            
            for i, chunk in enumerate(chunks):
                all_chunks.append(chunk)
                metadata.append({
                    'file': str(path),
                    'chunk_id': i,
                    'text': chunk[:200]  # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ï¼ˆæœ€åˆã®200æ–‡å­—ï¼‰
                })
        
        print(f"âœ… ç·ãƒãƒ£ãƒ³ã‚¯æ•°: {len(all_chunks)}")
        
        # åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
        print("ğŸ”„ åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆä¸­...")
        embeddings = self.model.encode(all_chunks, show_progress_bar=True)
        embeddings = np.array(embeddings).astype('float32')
        
        # FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
        print("ğŸ”„ FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆä¸­...")
        dimension = embeddings.shape[1]
        index = faiss.IndexFlatL2(dimension)
        index.add(embeddings)
        
        # ä¿å­˜
        KNOWLEDGE_DIR.mkdir(exist_ok=True)
        faiss.write_index(index, str(INDEX_FILE))
        with open(METADATA_FILE, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¿å­˜: {INDEX_FILE}")
        print(f"âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {METADATA_FILE}")
    
    def search(self, query: str, top_k: int = 3):
        """æ¤œç´¢"""
        self.load_model()
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­ã¿è¾¼ã¿
        if not INDEX_FILE.exists():
            print("âš ï¸ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            return
        
        self.index = faiss.read_index(str(INDEX_FILE))
        
        with open(METADATA_FILE, 'r', encoding='utf-8') as f:
            self.metadata = json.load(f)
        
        # ã‚¯ã‚¨ãƒªã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
        query_embedding = self.model.encode([query])
        query_embedding = np.array(query_embedding).astype('float32')
        
        # æ¤œç´¢å®Ÿè¡Œ
        distances, indices = self.index.search(query_embedding, top_k)
        
        # çµæœè¡¨ç¤º
        print(f"\nğŸ“Š æ¤œç´¢çµæœ (Top {top_k}):\n")
        for i, (idx, distance) in enumerate(zip(indices[0], distances[0])):
            meta = self.metadata[idx]
            print(f"ã€çµæœ {i+1}ã€‘")
            print(f"  ãƒ•ã‚¡ã‚¤ãƒ«: {Path(meta['file']).name}")
            print(f"  è·é›¢: {distance:.4f}")
            print(f"  ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: {meta['text']}")
            print()

def main():
    if len(sys.argv) < 2:
        print("ä½¿ã„æ–¹: python3 rag-index.py {index|search} [args...]")
        sys.exit(1)
    
    command = sys.argv[1]
    rag = RAGSystem()
    
    if command == "index":
        if len(sys.argv) < 3:
            print("ä½¿ã„æ–¹: python3 rag-index.py index <file1> <file2> ...")
            sys.exit(1)
        
        file_paths = sys.argv[2:]
        rag.create_index(file_paths)
    
    elif command == "search":
        if len(sys.argv) < 3:
            print("ä½¿ã„æ–¹: python3 rag-index.py search <query> [top_k]")
            sys.exit(1)
        
        query = sys.argv[2]
        top_k = int(sys.argv[3]) if len(sys.argv) > 3 else 3
        rag.search(query, top_k)
    
    else:
        print(f"âš ï¸ æœªçŸ¥ã®ã‚³ãƒãƒ³ãƒ‰: {command}")
        sys.exit(1)

if __name__ == "__main__":
    main()
