#!/usr/bin/env python3
"""
RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Clawdbotä½œæ¥­ãƒ­ã‚°ã‚’LanceDBã«ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦ä¿å­˜
"""

import os
import sys
import argparse
import json
from pathlib import Path
from datetime import datetime
import hashlib

try:
    import lancedb
    from sentence_transformers import SentenceTransformer
except ImportError as e:
    print(f"âŒ å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“: {e}", file=sys.stderr)
    print("å®Ÿè¡Œ: source /root/clawd/envs/rag/bin/activate && pip install lancedb sentence-transformers", file=sys.stderr)
    sys.exit(1)


class RAGIndexer:
    def __init__(self, db_path: str, collection_name: str):
        self.db_path = db_path
        self.collection_name = collection_name
        self.model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
        self.db = lancedb.connect(db_path)
        
    def extract_tasks_from_file(self, filepath: Path) -> list:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¿ã‚¹ã‚¯æƒ…å ±ã‚’æŠ½å‡º"""
        tasks = []
        
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸæŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯
            if filepath.suffix == '.md':
                tasks.extend(self._extract_from_markdown(content, filepath))
            elif filepath.suffix == '.sh':
                tasks.extend(self._extract_from_script(content, filepath))
            elif filepath.suffix in ['.js', '.py', '.ts']:
                tasks.extend(self._extract_from_code(content, filepath))
            elif filepath.name == 'lessons.md':
                tasks.extend(self._extract_from_lessons(content, filepath))
                
        except Exception as e:
            print(f"âš ï¸ {filepath} èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
            
        return tasks
    
    def _extract_from_markdown(self, content: str, filepath: Path) -> list:
        """Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¿ã‚¹ã‚¯ã‚’æŠ½å‡º"""
        tasks = []
        lines = content.split('\n')
        
        current_section = ""
        current_content = []
        
        for line in lines:
            if line.startswith('##'):
                # å‰ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿å­˜
                if current_section and current_content:
                    task_text = '\n'.join(current_content)
                    if len(task_text.strip()) > 50:  # 50æ–‡å­—ä»¥ä¸Šã®ã¿
                        tasks.append({
                            'text': task_text,
                            'title': current_section,
                            'source': str(filepath),
                            'type': 'markdown_section'
                        })
                
                # æ–°ã—ã„ã‚»ã‚¯ã‚·ãƒ§ãƒ³é–‹å§‹
                current_section = line.strip('# ').strip()
                current_content = []
            else:
                current_content.append(line)
        
        # æœ€å¾Œã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        if current_section and current_content:
            task_text = '\n'.join(current_content)
            if len(task_text.strip()) > 50:
                tasks.append({
                    'text': task_text,
                    'title': current_section,
                    'source': str(filepath),
                    'type': 'markdown_section'
                })
        
        return tasks
    
    def _extract_from_script(self, content: str, filepath: Path) -> list:
        """ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º"""
        tasks = []
        
        # ã‚¹ã‚¯ãƒªãƒ—ãƒˆå…¨ä½“ã‚’1ã¤ã®ã‚¿ã‚¹ã‚¯ã¨ã—ã¦æ‰±ã†
        if len(content.strip()) > 100:
            # ã‚³ãƒ¡ãƒ³ãƒˆã‹ã‚‰èª¬æ˜ã‚’æŠ½å‡º
            description_lines = []
            for line in content.split('\n')[:20]:  # æœ€åˆã®20è¡Œã‹ã‚‰ã‚³ãƒ¡ãƒ³ãƒˆæŠ½å‡º
                if line.strip().startswith('#') and not line.strip().startswith('#!'):
                    description_lines.append(line.strip('# ').strip())
            
            description = ' '.join(description_lines) if description_lines else f"Script: {filepath.name}"
            
            tasks.append({
                'text': content[:2000],  # æœ€åˆã®2000æ–‡å­—
                'title': description,
                'source': str(filepath),
                'type': 'script'
            })
        
        return tasks
    
    def _extract_from_code(self, content: str, filepath: Path) -> list:
        """ã‚³ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º"""
        tasks = []
        
        # é–¢æ•°ãƒ»ã‚¯ãƒ©ã‚¹å®šç¾©ã‚’æŠ½å‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
        if len(content.strip()) > 100:
            # ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã‚’1ã‚¿ã‚¹ã‚¯ã¨ã—ã¦æ‰±ã†
            tasks.append({
                'text': content[:2000],
                'title': f"Code: {filepath.name}",
                'source': str(filepath),
                'type': 'code'
            })
        
        return tasks
    
    def _extract_from_lessons(self, content: str, filepath: Path) -> list:
        """lessons.mdã‹ã‚‰å¤±æ•—äº‹ä¾‹ã‚’æŠ½å‡º"""
        tasks = []
        lines = content.split('\n')
        
        current_lesson = {}
        for line in lines:
            if line.startswith('## '):
                # å‰ã®ãƒ¬ãƒƒã‚¹ãƒ³ã‚’ä¿å­˜
                if current_lesson:
                    lesson_text = f"{current_lesson.get('title', '')}\n{current_lesson.get('symptom', '')}\n{current_lesson.get('cause', '')}\n{current_lesson.get('solution', '')}"
                    if len(lesson_text.strip()) > 50:
                        tasks.append({
                            'text': lesson_text,
                            'title': current_lesson.get('title', 'Unknown'),
                            'source': str(filepath),
                            'type': 'lesson'
                        })
                
                # æ–°ã—ã„ãƒ¬ãƒƒã‚¹ãƒ³é–‹å§‹
                current_lesson = {'title': line.strip('# ').strip()}
            elif line.startswith('**ç—‡çŠ¶**:'):
                current_lesson['symptom'] = line.strip()
            elif line.startswith('**åŸå› **:'):
                current_lesson['cause'] = line.strip()
            elif line.startswith('**è§£æ±ºç­–**:'):
                current_lesson['solution'] = line.strip()
        
        # æœ€å¾Œã®ãƒ¬ãƒƒã‚¹ãƒ³
        if current_lesson:
            lesson_text = f"{current_lesson.get('title', '')}\n{current_lesson.get('symptom', '')}\n{current_lesson.get('cause', '')}\n{current_lesson.get('solution', '')}"
            if len(lesson_text.strip()) > 50:
                tasks.append({
                    'text': lesson_text,
                    'title': current_lesson.get('title', 'Unknown'),
                    'source': str(filepath),
                    'type': 'lesson'
                })
        
        return tasks
    
    def index_directory(self, source_dir: Path, force: bool = False):
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å†å¸°çš„ã«ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ"""
        print(f"ğŸ“‚ ã‚¹ã‚­ãƒ£ãƒ³é–‹å§‹: {source_dir}")
        
        # æ—¢å­˜ãƒ†ãƒ¼ãƒ–ãƒ«ã®å‡¦ç†
        if force and self.collection_name in self.db.table_names():
            print(f"ğŸ—‘ï¸ æ—¢å­˜ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å‰Šé™¤: {self.collection_name}")
            self.db.drop_table(self.collection_name)
        
        all_tasks = []
        
        # å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
        patterns = ['**/*.md', '**/*.sh', '**/*.js', '**/*.py', '**/*.ts']
        exclude_dirs = {'node_modules', '.git', 'dist', 'build', '.next', '__pycache__', 'envs'}
        
        for pattern in patterns:
            for filepath in source_dir.glob(pattern):
                # é™¤å¤–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒã‚§ãƒƒã‚¯
                if any(ex in filepath.parts for ex in exclude_dirs):
                    continue
                
                tasks = self.extract_tasks_from_file(filepath)
                all_tasks.extend(tasks)
        
        print(f"ğŸ“Š æŠ½å‡ºã‚¿ã‚¹ã‚¯æ•°: {len(all_tasks)}")
        
        if not all_tasks:
            print("âš ï¸ ã‚¿ã‚¹ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        # ãƒ™ã‚¯ãƒˆãƒ«åŒ–
        print("ğŸ”„ ãƒ™ã‚¯ãƒˆãƒ«åŒ–ä¸­...")
        for task in all_tasks:
            task['vector'] = self.model.encode(task['text']).tolist()
            task['id'] = hashlib.md5(task['text'].encode()).hexdigest()
            task['timestamp'] = datetime.now().isoformat()
        
        # LanceDBã«ä¿å­˜
        print(f"ğŸ’¾ LanceDBã«ä¿å­˜ä¸­...")
        if self.collection_name in self.db.table_names():
            table = self.db.open_table(self.collection_name)
            table.add(all_tasks)
        else:
            table = self.db.create_table(self.collection_name, all_tasks)
        
        print(f"âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆå®Œäº†: {len(all_tasks)}ä»¶")


def main():
    parser = argparse.ArgumentParser(description='RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ')
    parser.add_argument('--source', required=True, help='ã‚½ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('--db', required=True, help='LanceDBãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('--collection', default='clawd_tasks', help='ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å')
    parser.add_argument('--force', action='store_true', help='å¼·åˆ¶å†æ§‹ç¯‰')
    
    args = parser.parse_args()
    
    source_path = Path(args.source)
    if not source_path.exists():
        print(f"âŒ ã‚½ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {args.source}", file=sys.stderr)
        sys.exit(1)
    
    indexer = RAGIndexer(args.db, args.collection)
    indexer.index_directory(source_path, force=args.force)


if __name__ == '__main__':
    main()
