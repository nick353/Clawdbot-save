#!/usr/bin/env python3
"""
é€±æ¬¡åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
éå»1é€±é–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
"""

import os
import sys
import json
from pathlib import Path
from datetime import datetime, timedelta
from collections import defaultdict

try:
    from google.oauth2 import service_account
    from googleapiclient.discovery import build
    from googleapiclient.errors import HttpError
except ImportError:
    print("âŒ Google API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    sys.exit(1)

# learning-engine.py ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append(str(Path(__file__).parent))
from learning_engine import LearningEngine

class WeeklyAnalyzer:
    def __init__(self, credentials_path=None, spreadsheet_id=None):
        self.credentials_path = credentials_path or os.getenv('GOOGLE_CREDENTIALS_PATH',
            '/root/clawd/skills/sns-growth-tracker/google-credentials.json')
        self.spreadsheet_id = spreadsheet_id or os.getenv('SNS_SHEETS_ID')
        
        if not self.spreadsheet_id:
            raise ValueError("SNS_SHEETS_ID ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # èªè¨¼
        self.credentials = service_account.Credentials.from_service_account_file(
            self.credentials_path,
            scopes=['https://www.googleapis.com/auth/spreadsheets']
        )
        
        self.service = build('sheets', 'v4', credentials=self.credentials)
        self.sheets = self.service.spreadsheets()
        
        # å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ³
        self.learning_engine = LearningEngine(credentials_path, spreadsheet_id)
    
    def analyze_week(self, week_offset=0):
        """
        é€±æ¬¡åˆ†æã‚’å®Ÿè¡Œ
        
        Args:
            week_offset: 0=ä»Šé€±ã€1=å…ˆé€±ã€2=å…ˆã€…é€±...
        
        Returns:
            dict: åˆ†æçµæœ
        """
        # é€±ã®é–‹å§‹æ—¥ã¨çµ‚äº†æ—¥ã‚’è¨ˆç®—
        today = datetime.now()
        monday = today - timedelta(days=today.weekday() + (7 * week_offset))
        sunday = monday + timedelta(days=6)
        
        period = f"{monday.strftime('%Y-%m-%d')} ï½ {sunday.strftime('%Y-%m-%d')}"
        week_number = monday.isocalendar()[1]
        
        # ãƒ‡ãƒ¼ã‚¿å–å¾—
        posts = self._get_week_posts(monday, sunday)
        experiments = self._get_week_experiments(monday, sunday)
        trends = self._get_week_trends(monday, sunday)
        
        # åˆ†æ
        platform_performance = self._analyze_platform_performance(posts)
        best_post = self._find_best_post(posts)
        worst_post = self._find_worst_post(posts)
        learnings = self._extract_learnings(posts, trends)
        
        # å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ³ã‹ã‚‰æ¨å¥¨äº‹é …
        learning_result = self.learning_engine.learn_from_past_data(days=30)
        
        # æ¬¡é€±ã®æˆ¦ç•¥
        next_week_strategy = self._generate_next_week_strategy(
            platform_performance,
            learnings,
            learning_result['recommendations']
        )
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = {
            'week': f"{monday.year}å¹´ ç¬¬{week_number}é€±",
            'period': period,
            'total_posts': len(posts),
            'experiments': len(experiments),
            'platform_performance': platform_performance,
            'best_post': best_post,
            'worst_post': worst_post,
            'learnings': learnings,
            'trends_discovered': len(trends),
            'next_week_strategy': next_week_strategy,
            'generated_at': datetime.now().isoformat()
        }
        
        # ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜
        self._save_report(report, monday)
        
        # Google Sheetsã«è¨˜éŒ²
        self._record_to_sheets(report)
        
        return report
    
    def _get_week_posts(self, start_date, end_date):
        """é€±ã®æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            result = self.sheets.values().get(
                spreadsheetId=self.spreadsheet_id,
                range='æŠ•ç¨¿ãƒã‚¹ã‚¿ãƒ¼!A:M'
            ).execute()
            
            values = result.get('values', [])
            if not values:
                return []
            
            headers = values[0]
            posts = []
            
            for row in values[1:]:
                if len(row) < len(headers):
                    row = row + [''] * (len(headers) - len(row))
                
                post = dict(zip(headers, row))
                
                try:
                    post_date = datetime.strptime(post['æŠ•ç¨¿æ—¥æ™‚'], '%Y-%m-%d %H:%M:%S')
                    if start_date <= post_date <= end_date:
                        # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                        post['engagement'] = self._get_post_engagement(post['æŠ•ç¨¿ID'])
                        posts.append(post)
                except:
                    continue
            
            return posts
        
        except HttpError as e:
            print(f"âŒ æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _get_post_engagement(self, post_id):
        """æŠ•ç¨¿ã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        engagement = {}
        
        for platform in ['X (Twitter)', 'Threads', 'Instagram', 'Facebook', 'Pinterest']:
            try:
                result = self.sheets.values().get(
                    spreadsheetId=self.spreadsheet_id,
                    range=f'{platform}!A:H'
                ).execute()
                
                values = result.get('values', [])
                if not values:
                    continue
                
                headers = values[0]
                
                for row in values[1:]:
                    if len(row) < 2:
                        continue
                    
                    if row[0] == post_id:
                        if len(row) < len(headers):
                            row = row + [''] * (len(headers) - len(row))
                        
                        engagement[platform] = dict(zip(headers, row))
                        break
            
            except:
                continue
        
        return engagement
    
    def _get_week_experiments(self, start_date, end_date):
        """é€±ã®å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            result = self.sheets.values().get(
                spreadsheetId=self.spreadsheet_id,
                range='å®Ÿé¨“ãƒ­ã‚°!A:K'
            ).execute()
            
            values = result.get('values', [])
            if not values:
                return []
            
            headers = values[0]
            experiments = []
            
            for row in values[1:]:
                if len(row) < len(headers):
                    row = row + [''] * (len(headers) - len(row))
                
                exp = dict(zip(headers, row))
                
                try:
                    exp_date = datetime.strptime(exp['å®Ÿæ–½æ—¥'], '%Y-%m-%d')
                    if start_date.date() <= exp_date.date() <= end_date.date():
                        experiments.append(exp)
                except:
                    continue
            
            return experiments
        
        except HttpError as e:
            return []
    
    def _get_week_trends(self, start_date, end_date):
        """é€±ã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            result = self.sheets.values().get(
                spreadsheetId=self.spreadsheet_id,
                range='ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ!A:K'
            ).execute()
            
            values = result.get('values', [])
            if not values:
                return []
            
            headers = values[0]
            trends = []
            
            for row in values[1:]:
                if len(row) < len(headers):
                    row = row + [''] * (len(headers) - len(row))
                
                trend = dict(zip(headers, row))
                
                try:
                    trend_date = datetime.strptime(trend['åˆ†ææ—¥'], '%Y-%m-%d')
                    if start_date.date() <= trend_date.date() <= end_date.date():
                        trends.append(trend)
                except:
                    continue
            
            return trends
        
        except HttpError as e:
            return []
    
    def _analyze_platform_performance(self, posts):
        """ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ"""
        performance = {}
        
        for platform in ['X (Twitter)', 'Threads', 'Instagram', 'Facebook', 'Pinterest']:
            rates = []
            
            for post in posts:
                engagement = post.get('engagement', {})
                if platform in engagement:
                    try:
                        rate = float(engagement[platform].get('ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡', 0))
                        if rate > 0:
                            rates.append(rate)
                    except:
                        pass
            
            if rates:
                performance[platform] = {
                    'avg_engagement': sum(rates) / len(rates),
                    'posts_count': len(rates),
                    'best_rate': max(rates),
                    'worst_rate': min(rates)
                }
            else:
                performance[platform] = {
                    'avg_engagement': 0,
                    'posts_count': 0,
                    'best_rate': 0,
                    'worst_rate': 0
                }
        
        return performance
    
    def _find_best_post(self, posts):
        """æœ€é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŠ•ç¨¿ã‚’ç‰¹å®š"""
        best_post = None
        best_rate = 0
        
        for post in posts:
            engagement = post.get('engagement', {})
            avg_rate = 0
            count = 0
            
            for platform, data in engagement.items():
                try:
                    rate = float(data.get('ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡', 0))
                    if rate > 0:
                        avg_rate += rate
                        count += 1
                except:
                    pass
            
            if count > 0:
                avg_rate /= count
                if avg_rate > best_rate:
                    best_rate = avg_rate
                    best_post = {
                        'post_id': post['æŠ•ç¨¿ID'],
                        'date': post['æŠ•ç¨¿æ—¥æ™‚'],
                        'theme': post.get('Geminiåˆ†æ', '')[:100],
                        'avg_engagement_rate': avg_rate,
                        'engagement': engagement
                    }
        
        return best_post
    
    def _find_worst_post(self, posts):
        """æœ€ä½ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŠ•ç¨¿ã‚’ç‰¹å®š"""
        worst_post = None
        worst_rate = float('inf')
        
        for post in posts:
            engagement = post.get('engagement', {})
            avg_rate = 0
            count = 0
            
            for platform, data in engagement.items():
                try:
                    rate = float(data.get('ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡', 0))
                    if rate > 0:
                        avg_rate += rate
                        count += 1
                except:
                    pass
            
            if count > 0:
                avg_rate /= count
                if avg_rate < worst_rate:
                    worst_rate = avg_rate
                    worst_post = {
                        'post_id': post['æŠ•ç¨¿ID'],
                        'date': post['æŠ•ç¨¿æ—¥æ™‚'],
                        'theme': post.get('Geminiåˆ†æ', '')[:100],
                        'avg_engagement_rate': avg_rate
                    }
        
        return worst_post
    
    def _extract_learnings(self, posts, trends):
        """å­¦ã³ã‚’æŠ½å‡º"""
        learnings = []
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰ã‹ã‚‰å­¦ã³
        for trend in trends:
            learning = trend.get('å­¦ã‚“ã ã“ã¨', '')
            if learning:
                learnings.append(learning)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã‹ã‚‰å­¦ã³
        if posts:
            # ãƒ†ãƒ¼ãƒåˆ¥ã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ
            theme_performance = defaultdict(list)
            
            for post in posts:
                theme = post.get('Geminiåˆ†æ', '')[:50]
                engagement = post.get('engagement', {})
                
                for platform, data in engagement.items():
                    try:
                        rate = float(data.get('ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡', 0))
                        if rate > 0:
                            theme_performance[theme].append(rate)
                    except:
                        pass
            
            # æœ€ã‚‚åŠ¹æœçš„ãªãƒ†ãƒ¼ãƒ
            if theme_performance:
                best_theme = max(theme_performance, key=lambda x: sum(theme_performance[x])/len(theme_performance[x]))
                avg_rate = sum(theme_performance[best_theme]) / len(theme_performance[best_theme])
                learnings.append(f"{best_theme} ãŒæœ€ã‚‚åŠ¹æœçš„ï¼ˆå¹³å‡{avg_rate:.2f}%ï¼‰")
        
        return learnings[:5]  # ä¸Šä½5å€‹
    
    def _generate_next_week_strategy(self, performance, learnings, recommendations):
        """æ¬¡é€±ã®æˆ¦ç•¥ã‚’ç”Ÿæˆ"""
        strategies = []
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒè‰¯ã„ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã«æ³¨åŠ›
        sorted_platforms = sorted(
            performance.items(),
            key=lambda x: x[1]['avg_engagement'],
            reverse=True
        )
        
        if sorted_platforms:
            best_platform = sorted_platforms[0][0]
            strategies.append(f"{best_platform}ã«æ³¨åŠ›ï¼ˆå¹³å‡ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ{sorted_platforms[0][1]['avg_engagement']:.2f}%ï¼‰")
        
        # å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ³ã‹ã‚‰ã®æ¨å¥¨äº‹é …
        for rec in recommendations[:3]:
            if rec['priority'] in ['high', 'medium']:
                strategies.append(rec['recommendation'])
        
        # å­¦ã³ã‚’æˆ¦ç•¥ã«åæ˜ 
        for learning in learnings[:2]:
            strategies.append(f"ç¶™ç¶š: {learning}")
        
        return strategies
    
    def _save_report(self, report, monday):
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        report_dir = Path(__file__).parent.parent / 'data' / 'reports'
        report_dir.mkdir(parents=True, exist_ok=True)
        
        report_file = report_dir / f"report-{monday.strftime('%Y-%m-%d')}.json"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # Markdownå½¢å¼ã§ã‚‚ä¿å­˜
        md_file = report_dir / f"report-{monday.strftime('%Y-%m-%d')}.md"
        md_content = self._format_report_markdown(report)
        
        with open(md_file, 'w', encoding='utf-8') as f:
            f.write(md_content)
        
        # latest-report.md ã‚’æ›´æ–°
        latest_file = report_dir / 'latest-report.md'
        with open(latest_file, 'w', encoding='utf-8') as f:
            f.write(md_content)
    
    def _format_report_markdown(self, report):
        """Markdownå½¢å¼ã§ãƒ¬ãƒãƒ¼ãƒˆæ•´å½¢"""
        md = f"""# ğŸ“Š SNSæˆé•·ãƒ¬ãƒãƒ¼ãƒˆï¼ˆ{report['week']}ï¼‰

**æœŸé–“**: {report['period']}  
**ç”Ÿæˆæ—¥æ™‚**: {datetime.fromisoformat(report['generated_at']).strftime('%Y-%m-%d %H:%M')}

---

## ğŸ“ˆ ç·åˆçµæœ

- **ç·æŠ•ç¨¿æ•°**: {report['total_posts']}ä»¶
- **å®Ÿé¨“æ•°**: {report['experiments']}ä»¶
- **ãƒˆãƒ¬ãƒ³ãƒ‰ç™ºè¦‹**: {report['trends_discovered']}ä»¶

---

## ğŸ† ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

"""
        
        # ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        for platform, perf in report['platform_performance'].items():
            md += f"### {platform}\n"
            md += f"- å¹³å‡ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡: **{perf['avg_engagement']:.2f}%**\n"
            md += f"- æŠ•ç¨¿æ•°: {perf['posts_count']}ä»¶\n"
            md += f"- æœ€é«˜: {perf['best_rate']:.2f}% / æœ€ä½: {perf['worst_rate']:.2f}%\n\n"
        
        # ãƒ™ã‚¹ãƒˆæŠ•ç¨¿
        if report['best_post']:
            best = report['best_post']
            md += f"""---

## ğŸŒŸ ãƒ™ã‚¹ãƒˆæŠ•ç¨¿

**æŠ•ç¨¿ID**: {best['post_id']}  
**æŠ•ç¨¿æ—¥æ™‚**: {best['date']}  
**å¹³å‡ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡**: {best['avg_engagement_rate']:.2f}%

**å†…å®¹**: {best['theme']}

"""
        
        # å­¦ã³
        if report['learnings']:
            md += "---\n\n## ğŸ“š ä»Šé€±ã®å­¦ã³\n\n"
            for i, learning in enumerate(report['learnings'], 1):
                md += f"{i}. {learning}\n"
            md += "\n"
        
        # æ¬¡é€±ã®æˆ¦ç•¥
        if report['next_week_strategy']:
            md += "---\n\n## ğŸ¯ æ¥é€±ã®æˆ¦ç•¥\n\n"
            for i, strategy in enumerate(report['next_week_strategy'], 1):
                md += f"{i}. {strategy}\n"
            md += "\n"
        
        md += "---\n\n*è‡ªå‹•ç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆ by SNS Growth Tracker*\n"
        
        return md
    
    def _record_to_sheets(self, report):
        """Google Sheetsã«è¨˜éŒ²"""
        try:
            row = [
                report['week'],
                report['period'],
                report['total_posts'],
                report['experiments'],
                report.get('best_post', {}).get('post_id', ''),
                self._get_best_platform(report['platform_performance']),
                self._get_avg_engagement(report['platform_performance']),
                '\n'.join(report['learnings']),
                '\n'.join(report['next_week_strategy'])
            ]
            
            self.sheets.values().append(
                spreadsheetId=self.spreadsheet_id,
                range='é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ!A:I',
                valueInputOption='USER_ENTERED',
                insertDataOption='INSERT_ROWS',
                body={'values': [row]}
            ).execute()
        
        except HttpError as e:
            print(f"âš ï¸  Google Sheetsè¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _get_best_platform(self, performance):
        """æœ€é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚’å–å¾—"""
        if not performance:
            return ''
        
        best = max(performance.items(), key=lambda x: x[1]['avg_engagement'])
        return best[0]
    
    def _get_avg_engagement(self, performance):
        """å…¨ä½“ã®å¹³å‡ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ã‚’è¨ˆç®—"""
        if not performance:
            return 0
        
        rates = [p['avg_engagement'] for p in performance.values() if p['avg_engagement'] > 0]
        return sum(rates) / len(rates) if rates else 0

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    week_offset = 0
    if len(sys.argv) > 1:
        week_offset = int(sys.argv[1])
    
    try:
        analyzer = WeeklyAnalyzer()
        report = analyzer.analyze_week(week_offset)
        
        print(json.dumps(report, ensure_ascii=False, indent=2))
    
    except Exception as e:
        print(json.dumps({
            'error': str(e),
            'week_offset': week_offset
        }, ensure_ascii=False, indent=2), file=sys.stderr)
        sys.exit(1)

if __name__ == '__main__':
    main()
